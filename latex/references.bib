% Anamnesis project references
% Auto-generated from research/phase0_report.md reference list
% 53 entries: [1] through [53]

@inproceedings{afzal2025,
  author    = {Afzal, Areeb and Matthes, Florian and Chechik, Gal and Ziser, Yftah},
  title     = {Knowing Before Saying: {LLM} Representations Encode Information About Chain-of-Thought Success Before Completion},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2025},
  year      = {2025},
  url       = {https://aclanthology.org/2025.findings-acl.662/},
}

@inproceedings{behrouz2025,
  author    = {Behrouz, Ali and Zhong, Peilin and Mirrokni, Vahab},
  title     = {Titans: Learning to Memorize at Test Time},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2025},
  eprint    = {2501.00663},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}

@article{betley2025a,
  author    = {Betley, Jan and Tan, Daniel and Warncke, Niels and others},
  title     = {Emergent Misalignment: Narrow Finetuning Can Produce Broadly Misaligned {LLMs}},
  journal   = {Nature},
  year      = {2026},
  note      = {Also ICML 2025 Oral (PMLR 267:4043--4068)},
  eprint    = {2502.17424},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{betley2025b,
  author    = {Betley, Jan and Cocola, Jett and Feng, David and others},
  title     = {Weird Generalization and Inductive Backdoors: New Ways to Corrupt {LLMs}},
  year      = {2025},
  eprint    = {2512.09742},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{boxo2025,
  author    = {Boxo, George and Raval, Suhail and others},
  title     = {Caught in the Act: A Mechanistic Approach to Detecting Deception},
  year      = {2025},
  eprint    = {2508.19505},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{brandon2024,
  author    = {Brandon, William and Mishra, Mayank and Nrusimha, Aniruddha and Panda, Rameswar and {Ragan Kelly}, Jonathan},
  title     = {Reducing Transformer Key-Value Cache Size with Cross-Layer Attention},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
  eprint    = {2405.12981},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{cai2024,
  author    = {Cai, Zefan and Zhang, Yichi and Gao, Bofei and others},
  title     = {{PyramidKV}: Dynamic {KV} Cache Compression Based on Pyramidal Information Funneling},
  year      = {2024},
  eprint    = {2406.02069},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{chen2025,
  author    = {Chen, Rian and Arditi, Andy and Sleight, Henry and Evans, Owain and Lindsey, Jack},
  title     = {Persona Vectors: Monitoring and Controlling Character Traits in Language Models},
  year      = {2025},
  eprint    = {2507.21509},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{li2025a,
  author    = {Li, Zihao and Song, Shuqi and Xi, Chenyang and others},
  title     = {{MemOS}: A Memory {OS} for {AI} System},
  year      = {2025},
  eprint    = {2507.03724},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
}

@misc{chua2025,
  author    = {Chua, James and Betley, Jan and Taylor, Meg and Evans, Owain},
  title     = {Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models},
  year      = {2025},
  eprint    = {2506.13206},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{cloud2025,
  author    = {Cloud, Alexander and Le, Matthew and Chua, James and others},
  title     = {Subliminal Learning: Language Models Transmit Behavioral Traits via Hidden Signals in Data},
  year      = {2025},
  eprint    = {2507.14805},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{do2025,
  author    = {Do, Vuong Duc and Tran, Quoc Huy and Venkatesh, Svetha and Le, Hung},
  title     = {Dynamic Steering with Episodic Memory for Large Language Models},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2025},
  year      = {2025},
  pages     = {13731--13749},
}

@inproceedings{dong2025,
  author    = {Dong, Zihao and others},
  title     = {Emergent Response Planning in {LLMs}},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2025},
  eprint    = {2502.06258},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{frising2025,
  author    = {Frising, Matteo and Balcells, Daniel},
  title     = {Linear Personality Probing and Steering in {LLMs}: A Big Five Study},
  year      = {2025},
  eprint    = {2512.17639},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{heo2025,
  author    = {Heo, Juyeon and {Heinze-Deml}, Christina and others},
  title     = {Do {LLMs} Know Internally When They Follow Instructions?},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2025},
  eprint    = {2410.14516},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{hewitt2019,
  author    = {Hewitt, John and Liang, Percy},
  title     = {Designing and Interpreting Probes with Control Tasks},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  year      = {2019},
  pages     = {2733--2743},
}

@inproceedings{huang2025,
  author    = {Huang, Jing and Tao, Jing and others},
  title     = {Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2025},
  eprint    = {2505.11770},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{lewis2020,
  author    = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and others},
  title     = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2020},
  eprint    = {2005.11401},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{li2023,
  author    = {Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  title     = {Inference-Time Intervention: Eliciting Truthful Answers from a Language Model},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2023},
  eprint    = {2306.03341},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{li2024,
  author    = {Li, Yuhui and Huang, Yingbing and Yang, Bowen and others},
  title     = {{SnapKV}: {LLM} Knows What You Are Looking for Before Generation},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
  eprint    = {2404.14469},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{liang2025,
  author    = {Liang, Zhengxuan and Li, Ruoyu and Zhou, Yitao and others},
  title     = {{CLUE}: Non-parametric Verification from Experience via Hidden-State Clustering},
  year      = {2025},
  eprint    = {2510.01591},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{liu2024,
  author    = {Liu, Zirui and Yuan, Jiayi and Jin, Hongye and others},
  title     = {{KIVI}: A Tuning-Free Asymmetric 2bit Quantization for {KV} Cache},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2024},
  eprint    = {2402.02750},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{zhang2025a,
  author    = {Zhang, Liang and Song, Dongliang and Wu, Zhaoyu and Tian, Yuan and Zhou, Chong and Xu, Jun and Yang, Zhoujun and Zhang, Shiliang},
  title     = {Detecting Hallucination in Large Language Models Through Deep Internal Representation Analysis ({MHAD})},
  booktitle = {Proceedings of the Thirty-Fourth International Joint Conference on Artificial Intelligence (IJCAI)},
  year      = {2025},
  pages     = {8357--8365},
}

@misc{packer2023,
  author    = {Packer, Charles and Wooders, Sarah and Lin, Kevin and others},
  title     = {{MemGPT}: Towards {LLMs} as Operating Systems},
  year      = {2023},
  eprint    = {2310.08560},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
}

@misc{pochinkov2025,
  author    = {Pochinkov, Nikita and others},
  title     = {{ParaScopes}: What Do Language Model Activations Encode About Future Text?},
  year      = {2025},
  eprint    = {2511.00180},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{qi2025,
  author    = {Qi, Yinan and others},
  title     = {{ParisKV}: Fast and Drift-Robust {KV}-Cache Retrieval for Long-Context {LLMs}},
  year      = {2025},
  eprint    = {2602.07721},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{reimers2019,
  author    = {Reimers, Nils and Gurevych, Iryna},
  title     = {Sentence-{BERT}: Sentence Embeddings using Siamese {BERT}-Networks},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2019},
  eprint    = {1908.10084},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{ramachandran2025,
  author    = {Ramachandran, Anirudh and others},
  title     = {{ThinKV}: Thought-Adaptive {KV} Cache Compression for Efficient Reasoning Models},
  year      = {2025},
  eprint    = {2510.01290},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{schrodi2025,
  author    = {Schrodi, Simon and Kempf, Elisabeth and Barez, Fazl and Brox, Thomas},
  title     = {Towards Understanding Subliminal Learning: When and How Hidden Biases Transfer},
  year      = {2025},
  eprint    = {2509.23886},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{servedio2025,
  author    = {Servedio, Giovanni and {De Bellis}, Armando and {Di Palma}, Dario and Anelli, Vito Walter and {Di Noia}, Tommaso},
  title     = {Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in {LLMs}},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year      = {2025},
  pages     = {6089--6104},
  url       = {https://aclanthology.org/2025.acl-long.304/},
}

@inproceedings{shelmanov2025,
  author    = {Shelmanov, Artem and Fadeeva, Ekaterina and others},
  title     = {A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection},
  booktitle = {Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2025},
  pages     = {35712--35731},
  eprint    = {2505.08200},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{shi2026,
  author    = {Shi, Zhipeng and others},
  title     = {Internalizing {LLM} Reasoning via Discovery and Replay of Latent Actions ({STIR})},
  year      = {2026},
  eprint    = {2602.04925},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{turner2023,
  author    = {Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and others},
  title     = {Steering Language Models with Activation Engineering ({ActAdd})},
  year      = {2023},
  eprint    = {2308.10248},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{vardhan2026,
  author    = {Vardhan, M. Sai and Teja, L. Srinivas},
  title     = {Disentangling Direction and Magnitude in Transformer Representations: A Double Dissociation Through {L2}-Matched Perturbation Analysis},
  year      = {2026},
  eprint    = {2602.11169},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{wang2023,
  author    = {Wang, Weizhi and Dong, Li and Cheng, Hao and others},
  title     = {Augmenting Language Models with Long-Term Memory ({LongMem})},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2023},
  eprint    = {2306.07174},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{wang2025a,
  author    = {Wang, Yiming and others},
  title     = {Chain-of-Embedding: Latent Space Chain-of-Embedding Enables Output-Free {LLM} Self-Evaluation},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2025},
}

@misc{wang2025b,
  author    = {Wang, Yang and others},
  title     = {{TARG}: Training-Free Adaptive Retrieval Gating for Efficient {RAG}},
  year      = {2025},
  eprint    = {2511.09803},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{xing2025,
  author    = {Xing, Zichao and Li, Xun and Zhen, Hui-Ling and Yuan, Mingxuan and Pan, Sinno Jialin},
  title     = {Beyond Speedup: Utilizing {KV} Cache for Sampling and Reasoning},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2026},
  note      = {Poster},
  eprint    = {2601.20326},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{wang2025c,
  author    = {Wang, Zhaohan and Xu, Chenhao},
  title     = {{ThoughtProbe}: Classifier-Guided {LLM} Thought Space Exploration via Probing Representations},
  booktitle = {Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2025},
}

@misc{wei2025,
  author    = {Wei, Ruoqian and Cao, Jing and others},
  title     = {{MLP} Memory: A Retriever-Pretrained Memory for Large Language Models},
  year      = {2025},
  eprint    = {2508.01832},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{wollschlager2025,
  author    = {Wollschl{\"a}ger, Tom and others},
  title     = {The Geometry of Refusal in Large Language Models: Concept Cones and Representational Independence},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2025},
  eprint    = {2502.17420},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{xiao2024,
  author    = {Xiao, Guangxuan and Tian, Yuandong and Chen, Beidi and Han, Song and Lewis, Mike},
  title     = {Efficient Streaming Language Models with Attention Sinks ({StreamingLLM})},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2024},
  eprint    = {2309.17453},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{yunoshev2026,
  author    = {yunoshev},
  title     = {Mood Axis: {LLM} Personality from Hidden States},
  year      = {2026},
  howpublished = {GitHub},
  url       = {https://github.com/yunoshev/mood-axis},
}

@misc{li2026,
  author    = {Li, Jiatong and Li, Yihong and Huang, Kuan-Hao},
  title     = {Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models},
  year      = {2026},
  eprint    = {2602.01654},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{zhang2023,
  author    = {Zhang, Zhenyu and Sheng, Ying and others},
  title     = {{H2O}: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2023},
  eprint    = {2306.14048},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{zhang2025b,
  author    = {Zhang, Andi and others},
  title     = {Reasoning Models Know When They're Right: Probing Hidden States for Self-Verification},
  booktitle = {Conference on Language Modeling (COLM)},
  year      = {2025},
  eprint    = {2504.05419},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{ni2025,
  author    = {Ni, Jing and others},
  title     = {{ReProbe}: Efficient Test-Time Scaling of Multi-Step Reasoning by Probing Internal States of {LLMs}},
  year      = {2025},
  eprint    = {2511.06209},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{zhong2024,
  author    = {Zhong, Wanjun and Guo, Lianghong and Gao, Qianhui and Ye, He and Wang, Yanlin},
  title     = {{MemoryBank}: Enhancing Large Language Models with Long-Term Memory},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2024},
  pages     = {19724--19731},
  eprint    = {2305.10250},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{zou2023,
  author    = {Zou, Andy and Phan, Long and Chen, Sarah and others},
  title     = {Representation Engineering: A Top-Down Approach to {AI} Transparency ({RepE})},
  year      = {2023},
  eprint    = {2310.01405},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{hooper2024,
  author    = {Hooper, Coleman and Kim, Sehoon and Mohammadzadeh, Hiva and others},
  title     = {{KVQuant}: Towards 10 Million Context Length {LLM} Inference with {KV} Cache Quantization},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
  eprint    = {2401.18079},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@inproceedings{zur2025,
  author    = {Zur, Ariel and Loftus, A. Robert and Orgad, Hadas and others},
  title     = {It's Owl in the Numbers: Token Entanglement in Subliminal Learning},
  booktitle = {NeurIPS 2025 Mechanistic Interpretability Workshop},
  year      = {2025},
  url       = {https://openreview.net/forum?id=auKgpBRzIW},
}

@misc{ali2025,
  author    = {Ali, Raza and Caso, Filippo and Irwin, Connor and Li{\`o}, Pietro},
  title     = {Entropy-Lens: The Information Signature of Transformer Computations},
  year      = {2025},
  eprint    = {2502.16570},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
}

@misc{gurnee2025,
  author    = {Gurnee, Wes and Ameisen, Emmanuel and Kauvar, Isaac and Tarng, Jack and Pearce, Adam and Olah, Chris and Batson, Joshua},
  title     = {When Models Manipulate Manifolds: The Geometry of a Counting Task},
  year      = {2025},
  note      = {Transformer Circuits Thread},
  eprint    = {2601.04480},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
}
